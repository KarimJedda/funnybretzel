<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>FunnyBretzel</title>
    <link href="https://karimjedda.github.io/funnybretzel/feed.xml" rel="self" />
    <link href="https://karimjedda.github.io/funnybretzel" />
    <updated>2019-01-15T19:57:14+01:00</updated>
    <author>
        <name>FunnyBretzel</name>
    </author>
    <id>https://karimjedda.github.io/funnybretzel</id>

    <entry>
        <title>Switching from Lektor to Publii and other things</title>
        <author>
            <name>FunnyBretzel</name>
        </author>
        <link href="https://karimjedda.github.io/funnybretzel/switching-from-lektor-to-publii.html"/>
        <id>https://karimjedda.github.io/funnybretzel/switching-from-lektor-to-publii.html</id>
            <category term="news"/>

        <updated>2019-01-14T18:21:36+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://karimjedda.github.io/funnybretzel/media/posts/8/bubusbro.png" alt="" />
                    My blog has been pretty inactive for two years now and I thought it's time to update it. One thing lead to another I lost the&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <img src="https://karimjedda.github.io/funnybretzel/media/posts/8/bubusbro.png" alt="" />
                <p>My blog has been pretty inactive for two years now and I thought it's time to update it. One thing lead to another I lost the drive where I had the backups of my blog built upon Lektor. So I had to start again from scratch and to be honest I didn't feel like going the same way again. I stumbled upon Publii not long ago and I thought I'd play around a bit and so far the experience has been boombastic so I switched. </p>
<p>I have built my very own markdown editor to format the posts for Lektor but right now the one built in in Publii does all the things and more. </p>
<p>I've also deactivated google analytics because I do not care about those metrics that much. Seems like they did not motivate me enough to publish or write so buh bye. And yeah GDPR and stuff. </p>
<p>See you around :) </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Datamining the next series to watch - part 1</title>
        <author>
            <name>FunnyBretzel</name>
        </author>
        <link href="https://karimjedda.github.io/funnybretzel/datamining-the-next-series-to-watch-part-1.html"/>
        <id>https://karimjedda.github.io/funnybretzel/datamining-the-next-series-to-watch-part-1.html</id>

        <updated>2019-01-14T18:14:46+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://karimjedda.github.io/funnybretzel/media/posts/3/dataminingayeeee.png" alt="" />
                    Datamining the next series to watch - part 1I tried to kind of automate the process of deciding which movie or series to watch next and&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <img src="https://karimjedda.github.io/funnybretzel/media/posts/3/dataminingayeeee.png" alt="" />
                <h1>Datamining the next series to watch - part 1</h1>
<div>I tried to kind of automate the process of deciding which movie or series to watch next and I ended up writing this instead.<hr></div>
<h2>Lots of stuff out there</h2>
<div>
<div>Winter came and is still coming hard here in Germany and to fight the daily boredom and the long nights, what better than some 13 Seasons 50 minutes episodes series? (¬‿¬)</div>
<div> </div>
One thing though, it's ultra boring to find which one of those bazillion series to watch. There are reviews, recommendations, pseudo random generators and even gurus you can call that tell you what to do. </div>
<p>I tried to go the reviews &amp; recommendation way but in the end, if I don't like the series, it didn't matter if some guy on a remote island commented "cool series fam 10/10 would recommend". So there goes half a week jerking around to find out what to watch. </p>
<p> </p>
<h2>So what's the dealy yo?</h2>
<p>After several unsuccessful hours looking for what I would waste thousands of hours of my life on, I decided to watch nothing and went out to discover the world, travel and take pilates hiking courses while eating vegan food.</p>
<p>Just kidding, I found another way.</p>
<p> </p>
<h2>What makes a good series?</h2>
<div>
<div>When you watch a series you actually hear stuff and see stuff and sometimes read stuff when you didn't take that language class back in the days. </div>
<div>
<ul>
<li>Watching stuff means that I can analyze video, images: cool story bro, I just have a Pentium 2 512Mb ram machine which means I can't unleash deep learning mayhem on 1080p videos </li>
<li>Hearing stuff means that I can analyze audio: sure, will do, but audio libraries are a pita to use, i'm on it though</li>
<li>Reading stuff: Bingo! <strong>NLP textual analysis LDA Semantic High Learning Deep Learning In between learning</strong> (buzzwords for some google juice), so yeah, I went the subtitle way to stay the closest possible to the content I am analyzing, and as far as possible from some subjective representation of it</li>
</ul>
</div>
Sweet, let's go for the subtitles. A subtitle is a file that looks like it's numbers, timestamps and some text on it (almost like a parking ticket). It presents itself like this (from Southpark):<br><br><img src="http://i.imgur.com/JlZmld5.png"><br>As you can see, it contains information about the duration of somebody talking, when they talk and also what they say. This simple text file has so much data it would make any advertising company (aka social network) so happy! I wish there was something like it but in real life, so you can listen to people while listening to some Kanye West or some Drake.<br><br><br>
<h2>Planning mayhem</h2>
<div>For starters, here's a "slaughter plan" like the Germans call it:</div>
<div>
<ul>
<li>DONE Find the data </li>
<li>DONE Get the data</li>
<li>DONE Clean the data</li>
<li>DONE Preprocess the data</li>
<li>DONE Store the data</li>
<li>DONE Query the data</li>
<li>DONE Define what I want from the data</li>
<li>DONE Do some stuff with the data</li>
</ul>
<div><i>Notice the EMACS org mode goodness going on.</i></div>
</div>
<div>It's always useful to plan steps at the higher level, it's the only way you'll achieve something. </div>
<h2>Executing the master plan</h2>
</div>
<p>Let me save you some time here and tell you that there are a million sources for subtitles online but the best ones are:</p>
<p> </p>
<ul>
<li><a href="http://fr.tvsubtitles.net/">TV Subtitles</a></li>
<li><a href="http://www.opensubtitles.org/fr">OpenSubtitles</a></li>
</ul>
<div>The second one is the most entertaining one since they no scope any ad blocker out there to display ads so that you can meet sensational Russian women. ʕ•ᴥ•ʔ</div>
<div> </div>
<div>So ok, which series should I choose?</div>
<div> </div>
<div>Just like any IT nerd, I went on reddit and I asked for help. Let's start with the best of breed and ask: <a href="https://www.reddit.com/r/television/comments/3px8wa/worst_tv_series_of_all_time/">what are the worst tv series according to you?</a> </div>
<div>I got a lot of comments on that one, which already shows that it's also a tough choice to decide which series NOT to watch. Oh boy.</div>
<div> </div>
<h2>Data Dictatorship</h2>
<div>I had to decide, so I've decided I'll get the subtitles for Bones, Breaking Bad, Criminal Minds, Dexter, Game of Thrones, House MD, House of Cards, How I met your mother, Louie, Mr. Robot, Sex and the City, Southpark, Suits, The Big Bang Theory, The Vampire Diaries and The Walking Dead. (I promise I'll do Star Trek too, in a second sprint)</div>
<div>This small sample was to try and find out how those series are structured, and this is what I'll be showing in part 1 of this little data exploration.</div>
<div> </div>
<h2>Booting up Eclipse</h2>
<div>I had to start somewhere so I obviously decided I'll install java. Joke aside, here's some code that'll get you the subtitles for a series for just one website. The imports are not so difficult to figure out. You go ahead and code the rest young padawan!</div>
<p> </p>
<pre>def get_subtitle(series_name, series_id, seasons):<br>    for i in xrange(seasons):<br>        season = str(i + 1)<br>        download_link = 'http://fr.tvsubtitles.net/download-' + series_id + '-' + season + '-en.html'<br>        r = requests.get(download_link)<br>        z = zipfile.ZipFile(StringIO.StringIO(r.content))<br>        directory = series_name + '/Season ' + season<br>        if not os.path.exists(directory):<br>            os.makedirs(directory)<br>        z.extractall(path=directory)</pre>
<p> </p>
<div>I got the data, but data from the internet is as dangerous as unprotected sex. So I had to be cautious and check for stuff like encoding, formatting, extensions, file (☞ﾟ∀ﾟ)☞ size, language and stuff like that.</div>
<div>But that is part of the data cleaning process which is boring and which NOBODY EVER tells you about in school. You always get that sequoia quechua plant data set which I call a unicorn dataset. You will never get any other dataset that is so clean from the interwebz. </div>
<div> </div>
<div>So, several HOURS of frustration later, we did it guys. The data is clean and ready to be analyyyyyzed. </div>
<div> </div>
<div><img src="http://i.imgur.com/YZ47tEa.png"></div>
<div> </div>
<div> </div>
<h2>Cool bro, now what?</h2>
<div>Let's define the goals of the analysis. This step requires that you already looked at the data and also that you have 2 neurons dedicated to creativity and open-mindedness. </div>
<div>I don't half-ass my work so here are the features I define as important:</div>
<p> </p>
<div>• Talk time: How much talk is there in a series?</div>
<div>
<div>• Talk frequency: How frequently do they talk and when?</div>
<div>• Episode/Movie duration: How long was the thing?</div>
<div>• Idle time: Slideshow time (only pictures on screen)</div>
<div>• Number of words</div>
<div>• Number of sentences</div>
<div>• Most used words</div>
<div>• Words length</div>
<div>• Sentence length</div>
<div>
<div>• Vocabulary richness: How much $$ the vocabulary owns</div>
<div>• Time to read: How long would it take you to read the subs?</div>
<div>• SMOG grade: How old do you have to be to understand it?</div>
<div>• Topic modeling: What are the topics?</div>
<div>• Summary: Ain't nobody got time for that</div>
<div>• Polarity: Doesn't involve bears</div>
<div>• Word usage: How are the words used?</div>
<div>• Sentence beginnings: How are the sentence structured?</div>
<div> </div>
<div>In order to do all of this stuff, I headed over to the awesome Python community and I was staggered that there is so much GOOD OL Stuff out there that the dataset is just begging for it to be analyzed.</div>
<div> </div>
<div>Here's a short recap of all the libraries involved in the project:</div>
<div>
<div>• Python has libraries, lots of them, using Python 2.7 (problem?)</div>
<div>• Parse subtitles: <u>pysrt</u></div>
<div>• Parse text: <u>textblob</u>, <u>sumy</u> (text summarizer), <u>re</u></div>
<div>• Analyze text: <u>gensim</u> (topic modelling), <u>spacy</u> (kick ass nltk), <u>readability</u> etc</div>
<div>• Various data manipulation: <u>pandas</u>, <u>numpy</u><u> </u></div>
<div>• Display and plots: <u>Wordcloud</u>, <u>matplotlib</u></div>
<p>• Download: <u>requests</u>, <u>BeautifulSoup</u>, <u>zipfile</u>    </p>
<p> </p>
<div>Don't worry, this will be available on my Github repo I guess someday, but it's the most hackathon code you'll ever have the privilege to load on your V8 engine. </div>
<div> </div>
<h2>Enough chit chat, the results please </h2>
<div>My friends know, I like to talk a lot when I feel good, and right now, I feel (ﾉ◕ヮ◕)ﾉ*:･ﾟ✧ delighted ✧ﾟ･: *ヽ(◕ヮ◕ヽ). </div>
<div>Ok, so I tested on that series called DEXTER, I bet you know it right? </div>
<div> </div>
<div>So here's how it looks:</div>
<div> </div>
<img src="http://i.imgur.com/4FOkGUp.png">
<p> </p>
<p>The average talk time for a Dexter episode is 30 minutes, and the average duration of an episode is 50 minutes. The talk density, defined by 30/50 is 0.6, which means 60% of the series is talking. You can notice that the talk time goes up the more we advance in the intrigue. But not by much, I'm still digging into the data but I'm sure this is due to the fact that they repeat a lot of stuff from the previous episode. </p>
<p>Next series! Sex and the City. </p>
<p>Ok so I don't like this series at all, and you'll know exactly why in the second part of the article. In the meantime, here is the time distribution:</p>
<p><img src="http://i.imgur.com/sSIJmGM.png"></p>
<p>The average talk time is 15 minutes and the episode duration is around 25 minutes. The talk density for this one is 15/25, which gives us 60% too! So, Sex and the City shows us that size doesn't matter, since it has the same density as Dexter, and both series have some arguable success for different demographics. </p>
<p>Let's mess with everyone's favorite now: Game of Thrones. </p>
<p><img src="http://i.imgur.com/qMGEfS5.png"></p>
<p>Nice curves! Notice how one is going down and the other is going up. I think there was something sketchy that came with the subtitles at episode 0 of Season 5. They started counting in Python! Yay!</p>
<p>Sweet, we have some preliminary results and the program works well. But this is just the tip of the ice cream cone.</p>
<blockquote>Let's dig deeper! </blockquote>
<p>Let's see how that looks like with movies. I picked out the top 10 4chan movies, and here are the results:</p>
<p><img src="http://i.imgur.com/8fcGoVu.png"></p>
<p>One thing we can derive from the above stuff is: It really doesn't matter if there is a lot of talk (Pulp Fiction, Fight Club..) or almost none (Space Odyssey, Lord of the Rings, Blade Runner..), there is a lot more to a good series/movie than just the words. </p>
<blockquote>Deeper!</blockquote>
<div><br>Let's look at the Star Wars episodes. The times differ with the ones you'll find online because I don't take into account the credits and other stuff.<br><img src="http://i.imgur.com/EcOAoTn.png"><br>It's cool to know that even if the duration stays roughly the same, the talk time <a href="https://www.youtube.com/watch?v=9APAHhIPhJE">goes down! DOWN! DOWN!</a>. There are lots of stuff that can go into explaining this behavior. I like to think that during the last decade, our visual cortex grew bigger while other stuff got compressed. This means, now more than ever, that we are visual creatures.<br>PS: I didn't like the last Episode that much. </div>
<p>If you're still reading, here's a potato for your patience. </p>
<p><img src="http://themetapicture.com/media/funny-Almirant-Ackbar-potato-trap.jpg"></p>
<blockquote>It goes deeper</blockquote>
<p>Up to now, it was some minor stuff. Now it gets interesting. What if, instead of watching the stuff, we only read the subtitles? How much life-hours would we waste instead of helping the other countries or advancing research?</p>
<p>So here it is. </p>
<blockquote>Useless knowledge: The average person reads 250 words per minute, which means you already wasted 7 minutes.</blockquote>
<p><img src="http://i.imgur.com/sf8a5cS.png"></p>
<p>In order to calculate these values, I took ALL the subtitles possible for a given format. Mr Robot has only 1 season for example.</p>
<p>This doesn't speak for itself so let's put it into context like Steve Jobs. A good example would be to see how thick a subtitles book would be. Here for some Maths:</p>
<p><img src="http://i.imgur.com/NegtkhW.png"></p>
<p>Two things before we continue, I don't use INCHES and my multiplications and additions are commutative. Not like that one dude explaining how (°ロ°)☝ 3 + 3 + 3 + 3 + 3 is not the same as 5 + 5 + 5 lol.</p>
<p>So here you got it, If you took the whole Game of Thrones series, printed out the subtitles, and sold it as a book, it won't be thicker than 4 stacked Playboy magazines (<a href="https://answers.yahoo.com/question/index?qid=20120126205024AAqBXtv">this dude was kind enough to measure the thickness</a>)</p>
<p><img src="http://i.imgur.com/T6BvA3I.png"></p>
<p>Each red line represents a full pocket sized book by the way, you can meditate on the other things on your free time.</p>
<blockquote>DEEEPAAAAAHH</blockquote>
<p>Sweet, now that we did some weird stuff, let's plot some eye candy and do some word clouds. Those clouds were generated with <a href="http://www.wordclouds.com/">an online javascript thingie</a>. Analyzing them is up to you but here you have, only for the first seasons:</p>
<p><img src="http://i.imgur.com/ZTnL7py.png"></p>
<p><img src="http://i.imgur.com/2FOsT0k.png"></p>
<p>aaaaaand ༼ つ ◕_◕ ༽つ</p>
<p><img src="http://i.imgur.com/Az1Z2vL.jpg"></p>
<p>My writing as a therapy hits its end, I still have a lot I want to share but it's not yet formatted well so stay tuned if you want to know what makes a good series/movie. I found some characteristics using a mix of sound/video and text. If I'm too lazy just send me a message and we can talk code like ultra nerds.</p>
<p> </p>
<p>I did some NLP stuff but it gets really complicated plotting it and showing in a user friendly way. My javascript skills go as far as console.log is required and don't even start me on React.</p>
<p>But here's a little preview for part 2 though, that will be available on this blag:</p>
<p> </p>
<ul>
<li>Every point of view is unique, counting stars or just the simple fact of AVERAGING review counts or ratings is fundamentally flawed for series, even if your SVM's and KNN's go their way. This approach <strong><u><i>works</i></u></strong> for politics. ლ(´ڡ`ლ)</li>
<li>Them feels, not them bits </li>
<li>Closer to the content aka DEEPER!</li>
<li>Exploring hidden paths</li>
</ul>
<blockquote>Note: If you plan to aggressively throw the dataset into an RNN and generate a series or movie and record it, first of all you're awesome and second, I'd be glad to help you with the scenario and set up! </blockquote>
<p> </p>
<p>Thanks for reading, you're awesome! </p>
</div>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Control your server using Whatsapp</title>
        <author>
            <name>FunnyBretzel</name>
        </author>
        <link href="https://karimjedda.github.io/funnybretzel/control-your-server-using-whatsapp.html"/>
        <id>https://karimjedda.github.io/funnybretzel/control-your-server-using-whatsapp.html</id>

        <updated>2019-01-14T18:14:14+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://karimjedda.github.io/funnybretzel/media/posts/2/memoryusage.png" alt="" />
                    I still haven't found a decent command line app for Android/iPhone. I really need that because I can't always carry my computer around to manage my&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <img src="https://karimjedda.github.io/funnybretzel/media/posts/2/memoryusage.png" alt="" />
                <p>I still haven't found a decent command line app for Android/iPhone. I really need that because I can't always carry my computer around to manage my server. I tested some few apps, even IFTTT to automate some stuff, but you can't achieve anything groundbreaking with that.</p>
<p>Lately, I've been working on a project to automate lots of stuff on a continent wide scale... My programs sometimes fail, sometimes they work well but I need to supervise them. They are not even 6 months old.</p>
<p>So in order to stay in touch with my beloved servers, I coded this bot to control any machine remotely, using whatsapp - cron jobs didn't do the job anymore.</p>
<p>Why Whatsapp? Because I always have my phone with me.</p>
<p>I present to you, my Whatsapp command line remote control utility. Or whatsappcli. It works like a Slack bot, but it allows you way more than a simple slack bot.</p>
<p>You can use it to execute some predefined python functions or to execute commands on a shell, as if you were in front of your computer:</p>
<p>Here it is executing a simple ls: <img src="http://funnybretzel.com/images/2015/Screenshot_2015-10-19-19-49-13.png" alt=""></p>
<p>Or here it is to get the memory usage of my mac: <img src="http://funnybretzel.com/images/2015/Screenshot_2015-10-19-19-54-24.png" alt=""></p>
<p>It can also send simple images (think of a screenshot or anything image related) and tell jokes (Google TTS powered): <img src="http://funnybretzel.com/images/2015/Screenshot_2015-10-19-19-58-04.png" alt=""></p>
<p>For those Defcon people, it can be used as a dead man's switch, as in "delete all porn".</p>
<p>You can find the code here <a href="https://github.com/KarimJedda/whatsappcli">https://github.com/KarimJedda/whatsappcli</a>, it's barebones and you can adapt it to your specific needs. (It's adapted on another programmers code) In order to do that, you should only edit the routes.py file.</p>
<p>There is 0 security at the moment, because I would don't know where to begin or what to look for.</p>
<p>Telegram can also be used, but I don't need that app. yet.</p>
<p>Have fun with it.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Datamining a flat in Munich</title>
        <author>
            <name>FunnyBretzel</name>
        </author>
        <link href="https://karimjedda.github.io/funnybretzel/datamining-a-flat-in-munich-2.html"/>
        <id>https://karimjedda.github.io/funnybretzel/datamining-a-flat-in-munich-2.html</id>

        <updated>2019-01-14T18:15:11+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://karimjedda.github.io/funnybretzel/media/posts/7/flathunt.png" alt="" />
                    When you're in your mid-twenties, just got employed and don't have enough cash, finding an affordable flat in Munich is very difficult. Munich ranks 13th in&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <img src="https://karimjedda.github.io/funnybretzel/media/posts/7/flathunt.png" alt="" />
                <p>When you're in your mid-twenties, just got employed and don't have enough cash, finding an affordable flat in Munich is very difficult. Munich ranks 13th in the <a href="http://www.globalpost.com/dispatch/news/culture-lifestyle/traveltourism/120920/most-expensive-world-cities-cost-of-living-UBS">20 Most expensive cities on the planet</a></p>
<p>Honestly, I didn't need this article to figure that out but anyways, basically, there is too much demand, and very few reasonnable offers. Reasonnable means that the rent doesn't exceed 800€ for a 15m² flat.</p>
<p>It took me more than one year to find a flat, here is my story about how I datamined the flat search in Munich, and how I conducted some psychological experiments at the same time.</p>
<p>I started my search 4 months before I had to go to Munich. There are three options to find a flat here. A couple of websites (including facebook groups) to apply for accomodations, appartment rental agencies and some shady forums on which you can seldomly find some adverts. Appartment rental agencies cost roughly 3 times the monthly rent, which accounts for around 2000€. No need to say this was a no go for me as I prefer keeping that money and making something good out of it.</p>
<p>Anyways, I kept going with the two other options.</p>
<p>First impression: When applying online to any of those adverts (websites and forums) I almost never got an answer. I got like 1 negative answer for every 100 e-mails sent out.</p>
<p>Pretty shitty conversion rate, right ?</p>
<p>4 months passed and here I am in Munich, couchsurfing at a friend's place. I really needed to find my place, where I can feel at home. I was thinking how it was easier to find a place in Paris. . .</p>
<p>Anyways, tired of clicking daily on the same links, same adverts to get to apply for something, I decided to automatize the whole process.</p>
<p>First thing, was to get all the data from all the websites, and analyze it as if I was browsing myself. A handy Python utility called <a href="http://scrapy.org/">Scrapy</a> turned out very handy. I basically used this tool to crawl each and every website which got adverts for accomodations. I started by making a spider that goes through every website and gets me the data and store it locally as a json file:</p>
<p><a href="http://img.svbtle.com/0wd5a7wnunu67w.png"><img src="https://d23f6h5jpj26xu.cloudfront.net/0wd5a7wnunu67w_small.png" alt="1.png"></a></p>
<p>I had then to parse the results from the websites, and get clean data, this was done easily in Python with the json library.</p>
<p>The data I crawled was simple: some images, the price of the flat, the size of the flat, the email and number of the people renting the flat and some additional information:</p>
<p><a href="http://img.svbtle.com/z8qbhxuqgydsa.png"><img src="https://d23f6h5jpj26xu.cloudfront.net/z8qbhxuqgydsa_small.png" alt="3.png"></a></p>
<p>I then automated the script to be runned everyday and curated for me the coolest potential flats I could spend my time calling and sending e-mails to. I got everything daily per e-mail at 12:00. This helped me improve my conversion rate, I got almost 2 flat visiting each month and I spent less time searching. But this was not enough. Not enough for me. I wanted the tool to do all the work for me while I was dancing and enjoying the music in <a href="http://www.rote-sonne.com/index2.html">Rote Sonne</a>.</p>
<p>So I iterated again on this idea, this time I wanted my tool to automatically send emails to people.</p>
<p>I decided to use <a href="http://wwwsearch.sourceforge.net/mechanize/">Mechanize</a> to automatically answer to adverts selected by my super crawler. This was pretty easy as there is absolutely no captcha system used by that time, on those websites. So, this was set up pretty easily. And on the next day, it was answering automatically to e-mails, and I got all the answers back, when there were answers.</p>
<p>Then, I got this idea that bugged me, why are people not answering to me? There may be lots of answers to this question from which I kept the most important one: What is the number of people answering to an advert. This one was easy to test, I set up a fake advert and I got 97 answers, in 3hours. And 459 answers in 3 days.</p>
<p><a href="http://img.svbtle.com/ew2mlewf9fsrvw.png"><img src="https://d23f6h5jpj26xu.cloudfront.net/ew2mlewf9fsrvw_small.png" alt="anfragen.png"></a></p>
<p>So basicly, competition is insanely rude, each time I answered to some advert that was older than 3 days, I had like 0.2% chances of getting an answer. Haha.</p>
<p>Conclusion: I had to be the first one who answers to any advert. Easy to set up so I did it. But still, the answers, were like 4 per week. Basicly, while I was visiting a flat, my minions were working for me and answering to other adverts. I then wanted to continue to test this tool and find my perfect flat.</p>
<p>I wanted to know why I didn't get a 80% answer rate, so I started experimenting with the variables I had to fill out in the forms:</p>
<ul>
<li>A message</li>
<li>A name</li>
<li>A number</li>
<li>An email</li>
</ul>
<p>I A/B tested messages, numbers, names and emails. For this, I set up 80 email adresses that where routed to one single master email. I chose this number in order to optimize the answer rate to the maximum. For example: If someone answers to one of those 80 emails, the same person gets the answer in the end: Me.</p>
<p>So, everything was set up, and I had fun with the names, I used a fake name generator to get the names and the details. The messages came from a txt file which had defined message templates.</p>
<p>The conclusion from this little study, is that a girl with an italian name, gets an 90% answer rate, a guy with an arab name and is younger than 25 gets, 1% answer rate. The master of all, is the young munich guy who is around 25 , called Hanz who almost gets an answer all the time.</p>
<p>By that time, I found my dream flat and I am happy with it. The funny thing is that I found the flat through a friend. I then stopped my programs from turning.</p>
<p>Thanks.</p>
<p>Originally posted on: <a href="http://funnybretzel.svbtle.com/datamining-a-flat-in-munich">http://funnybretzel.svbtle.com/datamining-a-flat-in-munich</a></p>
            ]]>
        </content>
    </entry>
</feed>
